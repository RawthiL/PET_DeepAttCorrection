{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib plots within notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import platform\n",
    "print(\"python: \"+platform.python_version())\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "import os, shutil, sys\n",
    "\n",
    "sys.path.insert(0, '.')\n",
    "from DeepAttCorr_lib import GAN_3D_lib as GAN\n",
    "from DeepAttCorr_lib import data_handling as DH\n",
    "from DeepAttCorr_lib import file_manage_utils as File_mng\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "print('Using TensorFlow version: '+tf.__version__)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths and Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network name\n",
    "NETWORK_NAME = 'DeepAttCorr_ProGAN_Network'\n",
    "\n",
    "# Dataset location\n",
    "DATASET_PATH = './datasets/'\n",
    "\n",
    "# Checkpoint location\n",
    "CHECKPOINT_PATH = \"./Outputs/\"+NETWORK_NAME+\"/\"\n",
    "\n",
    "# Path to tensorboard desired output\n",
    "TENSORBOARD_BASE_PATH = \"./TensorBoard_output\"\n",
    "TENSORBOARD_OUT_PATH = os.path.join(TENSORBOARD_BASE_PATH,NETWORK_NAME)\n",
    "TENSORBOARD_OUT_PATH_TRAIN = os.path.join(TENSORBOARD_OUT_PATH,\"train\")\n",
    "TENSORBOARD_OUT_PATH_VALIDATION = os.path.join(TENSORBOARD_OUT_PATH,\"test\")\n",
    "\n",
    "# Clear outputs before running\n",
    "CLEAR_OUTS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imput volume size\n",
    "voxels_X = 128\n",
    "voxels_Y = 128\n",
    "voxels_Z = 32\n",
    "input_size = (voxels_X,voxels_Y,voxels_Z)\n",
    "\n",
    "# Number of resulotion compressions to be applies. \n",
    "# The lowest resolution (and start of the progressive GAN)\n",
    "# is at full_resolution/2**LOW_RES_POW\n",
    "LOW_RES_POW =4\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# ---------------------- GENERATOR -----------------------------------------------\n",
    "# --------------------------------------------------------------------------------\n",
    "# Network convolutional channels by resolution level\n",
    "USE_GEN_net_conv_Channels = [10, 20, 40, 80, 160]\n",
    "# Convolutional layers by resolution level\n",
    "USE_GEN_net_conv_Layers = 2\n",
    "# Use batch normalization for generator training\n",
    "USE_GEN_BATCH_NORM = False\n",
    "# Use pixel normalization for generator training\n",
    "USE_GEN_PIXEL_NORM = True\n",
    "# Use He scalling of weights for generator\n",
    "USE_GEN_HE_SCALLING = True\n",
    "# Wheight initialization standard deviation\n",
    "USE_GEN_INI_STD = 1.0\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# ---------------------- DISCRIMNATOR --------------------------------------------\n",
    "# --------------------------------------------------------------------------------\n",
    "# If true the discriminator recieves the generator output AND input latent space\n",
    "IS_CONDITIONAL_DISC = True\n",
    "# Network convolutional channels by resolution level\n",
    "USE_DISC_net_conv_Channels = [16, 32, 64, 128, 256]\n",
    "# Use weight norm constraint\n",
    "USE_DISC_NORM_CONSTRAINT_SCALE = False\n",
    "# Use mini batch std\n",
    "USE_DISC_MINI_BATCH_STD = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset full size (without slicing)\n",
    "DATASET_X_size = 128\n",
    "DATASET_Y_size = 128\n",
    "DATASET_Z_size = 256\n",
    "\n",
    "# Uniform or custom sampling of the input FOV\n",
    "# If True the input sample is sliced with uniform probability\n",
    "# If False, the Cumulative Density Function in CDF_PATH will control the sampling\n",
    "UNIFORM_SAMPLING = False\n",
    "CDF_PATH = \"./DeepAttCorr_lib/cdf_coef.npy\"\n",
    "\n",
    "\n",
    "# Volume mini-batch size\n",
    "BATCH_SIZE_TRAIN = 4\n",
    "BUFFER_SIZE_TRAIN = 4\n",
    "BATCH_SIZE_VALIDATION = 4\n",
    "BUFFER_SIZE_VALIDATION = 4\n",
    "\n",
    "\n",
    "# Initial step size\n",
    "step_size_gen = 0.0001\n",
    "step_size_disc = 0.0005\n",
    "\n",
    "# Set training functions\n",
    "TRAINING_FUNCTION_DISC = GAN.train_support.train_step_discriminator_conditional_3D_GAN_tf\n",
    "TRAINING_FUNCTION_GEN = GAN.train_support.train_step_generator_conditional_3D_GAN_tf\n",
    "\n",
    "# Total number of training steps to perform on each\n",
    "# resolution phase for the full models:\n",
    "STEPS_PER_PHASE = [1501, 3001, 6001, 8001, 18001]\n",
    "# and the Fade-In models\n",
    "STEPS_PER_PHASE_FADEIN = [1, 1001, 2001, 4001, 5001]\n",
    "# Number of steps per information print\n",
    "STEPS_PER_PRINT = 100\n",
    "# Number of steps per plotting of progress\n",
    "STEPS_PER_PLOTS = 500\n",
    "# Number of steps per checkpoint\n",
    "STEPS_PER_SAVE = 500\n",
    "# Initial number of discriminator training steps\n",
    "steps_disc_per_gen_ini = 500\n",
    "# Number of discriminator training steps per generator training steps\n",
    "steps_disc_per_gen_loop = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_mng.check_create_path('CHECKPOINT_PATH', CHECKPOINT_PATH, clear_folder=CLEAR_OUTS)\n",
    "File_mng.check_create_path('TENSORBOARD_BASE_PATH', TENSORBOARD_BASE_PATH)\n",
    "File_mng.check_create_path('TENSORBOARD_OUT_PATH', TENSORBOARD_OUT_PATH, clear_folder=CLEAR_OUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sampling CDF\n",
    "cdf_coef = [1.0]\n",
    "if not UNIFORM_SAMPLING:\n",
    "    cdf_coef = np.load(CDF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set multip-GPU mirror strategy\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset list\n",
    "# This list will contain a dataset for each resolution\n",
    "train_datasets_list = list()\n",
    "validation_datasets_list = list()\n",
    "\n",
    "train_datasets_dist_list = list()\n",
    "validation_datasets_dist_list = list()\n",
    "\n",
    "for idx_resol in range(LOW_RES_POW):\n",
    "\n",
    "    voxels_X_low_res = int(voxels_X/(2**(idx_resol)))\n",
    "    voxels_Y_low_res = int(voxels_Y/(2**(idx_resol)))\n",
    "    voxels_Z_low_res = int(voxels_Z/(2**(idx_resol)))\n",
    "    input_size_low_res = (voxels_X_low_res,voxels_Y_low_res,voxels_Z_low_res)\n",
    "    print('Setting up dataset for resolution: (%d,%d,%d)'%(input_size_low_res[0],\n",
    "                                                         input_size_low_res[1],\n",
    "                                                         input_size_low_res[2]))\n",
    "    \n",
    "    \n",
    "\n",
    "    # Dataset reading and agumentation function\n",
    "    data_size = np.array([int(DATASET_X_size/((2**idx_resol))), \n",
    "                          int(DATASET_Y_size/((2**idx_resol))), \n",
    "                          int(DATASET_Z_size/((2**idx_resol)))])\n",
    "\n",
    "    input_size_this = (voxels_X_low_res,voxels_Y_low_res,voxels_Z_low_res)\n",
    "\n",
    "    train_dataset_name = 'Train_Dataset_%dx%dx%d.tfrecord'%(data_size[0],data_size[1],data_size[2])\n",
    "    validation_dataset_name = 'Validation_Dataset_%dx%dx%d.tfrecord'%(data_size[0],data_size[1],data_size[2])\n",
    "    print('\\tLoading train dataset: %s'%train_dataset_name)\n",
    "    print('\\tLoading validation dataset: %s'%validation_dataset_name)\n",
    "\n",
    "\n",
    "    PATH_TFRECORD_TRAIN = os.path.join(DATASET_PATH, train_dataset_name)\n",
    "    PATH_TFRECORD_VALIDATION = os.path.join(DATASET_PATH, validation_dataset_name)\n",
    "\n",
    "    dataset_train_GAN = tf.data.TFRecordDataset(PATH_TFRECORD_TRAIN)\n",
    "    dataset_validation_GAN = tf.data.TFRecordDataset(PATH_TFRECORD_VALIDATION)\n",
    "\n",
    "    if voxels_X_low_res <= 32: \n",
    "        dataset_train_GAN = dataset_train_GAN.cache()\n",
    "        dataset_validation_GAN = dataset_validation_GAN.cache()\n",
    "        print('\\tUsing cache for dataset: %s'%train_dataset_name)\n",
    "\n",
    "    # Create train dataset with transformations\n",
    "    dataset_train_GAN = dataset_train_GAN.map(lambda x: DH.tf_read_sample_file(x, \n",
    "                                                                               data_size, \n",
    "                                                                               input_size_this, \n",
    "                                                                               not_transformed = True,\n",
    "                                                                               cdf_sampler_coef=cdf_coef))\n",
    "\n",
    "    # Create validation dataset, whole image\n",
    "    dataset_validation_GAN = dataset_validation_GAN.map(lambda x: DH.tf_read_raw_sample(x, data_size))\n",
    "    \n",
    "    # Shuffle the train dataset\n",
    "    dataset_train_GAN = dataset_train_GAN.shuffle(buffer_size=BUFFER_SIZE_TRAIN, reshuffle_each_iteration=True).repeat(-1)\n",
    "\n",
    "\n",
    "    # Set batch size\n",
    "    dataset_train_GAN = dataset_train_GAN.batch(batch_size=BATCH_SIZE_TRAIN)\n",
    "    dataset_validation_GAN = dataset_validation_GAN.batch(batch_size=BATCH_SIZE_VALIDATION)\n",
    "    \n",
    "    train_datasets_list.append(dataset_train_GAN)\n",
    "    validation_datasets_list.append(dataset_validation_GAN)\n",
    "\n",
    "    # Distributed version\n",
    "    dist_dataset_train_GAN = strategy.experimental_distribute_dataset(dataset_train_GAN)\n",
    "    dist_dataset_validation_GAN = strategy.experimental_distribute_dataset(dataset_validation_GAN)\n",
    "    \n",
    "    train_datasets_dist_list.append(dist_dataset_train_GAN)\n",
    "    validation_datasets_dist_list.append(dist_dataset_validation_GAN)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation -- Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progressive Pix2Pix 3D Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    # Create parameter structure\n",
    "    param_generator = GAN.topologies.ProGAN_param_structure()\n",
    "\n",
    "    param_generator.block_conv_channels = USE_GEN_net_conv_Channels\n",
    "    param_generator.n_blocks = len(param_generator.block_conv_channels) \n",
    "    param_generator.latent_dim = (voxels_X/(2**(LOW_RES_POW-1)),\n",
    "                                  voxels_Y/(2**(LOW_RES_POW-1)),\n",
    "                                  voxels_Z/(2**(LOW_RES_POW-1)),1)\n",
    "    param_generator.block_conv_layers = USE_GEN_net_conv_Layers\n",
    "\n",
    "    param_generator.use_BatchNorm = USE_GEN_BATCH_NORM\n",
    "    param_generator.use_PixelNorm = USE_GEN_PIXEL_NORM\n",
    "    param_generator.use_He_scale = USE_GEN_HE_SCALLING\n",
    "    param_generator.initializer_std = USE_GEN_INI_STD\n",
    "\n",
    "\n",
    "\n",
    "    # Create the list of progressive growing models\n",
    "    generator_model_list = GAN.topologies.define_3D_prog_Vnet_generator(param_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator_model_list[1][1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all models topologies\n",
    "for i in range(LOW_RES_POW):\n",
    "    tf.keras.utils.plot_model(generator_model_list[i][0], to_file=os.path.join(CHECKPOINT_PATH,'ProgPix2Pix3D_generator_model_dilat_%d.png'%i), show_shapes=True, show_layer_names=True)\n",
    "    tf.keras.utils.plot_model(generator_model_list[i][1], to_file=os.path.join(CHECKPOINT_PATH,'ProgPix2Pix3D_generator_model_dilat_%d_FadeIn.png'%i), show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Progrssive Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    # Create parameter structure\n",
    "    param_disc = GAN.topologies.Disc_param_structure()\n",
    "    param_disc.conditional = IS_CONDITIONAL_DISC\n",
    "    param_disc.block_conv_channels = USE_DISC_net_conv_Channels\n",
    "\n",
    "    param_disc.input_shape = (voxels_X/(2**(LOW_RES_POW-1)),\n",
    "                              voxels_Y/(2**(LOW_RES_POW-1)),\n",
    "                              voxels_Z/(2**(LOW_RES_POW-1)),1)\n",
    "\n",
    "    param_disc.use_norm_contrain_scale = USE_DISC_NORM_CONSTRAINT_SCALE\n",
    "    param_disc.use_minibatch_stdev = USE_DISC_MINI_BATCH_STD\n",
    "\n",
    "    param_disc.n_blocks = len(param_disc.block_conv_channels) \n",
    "\n",
    "    param_disc.downSampling_layers  = len(param_disc.block_conv_channels) \n",
    "\n",
    "\n",
    "    # Create the list of progressive growing models\n",
    "    disc_model_list = GAN.topologies.define_discriminator_3D(param_disc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "disc_model_list[1][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save all models topologies\n",
    "for i in range(LOW_RES_POW):\n",
    "    tf.keras.utils.plot_model(disc_model_list[i][0], to_file=os.path.join(CHECKPOINT_PATH,'ProgPix2Pix3D_discriminator_model_dilat_%d.png'%i), show_shapes=True, show_layer_names=True)\n",
    "    tf.keras.utils.plot_model(disc_model_list[i][1], to_file=os.path.join(CHECKPOINT_PATH,'ProgPix2Pix3D_discriminator_model_dilat_%d_FadeIn.png'%i), show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizers and metrics for training \n",
    "\n",
    "with strategy.scope():\n",
    "    \n",
    "   \n",
    "    optimizer_gen = keras.optimizers.Adam(lr=step_size_gen, beta_1=0, beta_2=0.99, epsilon=1.0e-8)\n",
    "    optimizer_disc = keras.optimizers.RMSprop(step_size_disc)\n",
    "    \n",
    "    train_d1_loss = keras.metrics.Mean(name='train_d1_loss')\n",
    "    train_d2_loss = keras.metrics.Mean(name='train_d2_loss')\n",
    "    train_dgrad_loss = keras.metrics.Mean(name='train_dgrad_loss')\n",
    "    \n",
    "    train_g_loss = keras.metrics.Mean(name='train_g_loss')\n",
    "    train_g_comp_loss = keras.metrics.Mean(name='train_g_comp_loss')\n",
    "    \n",
    "\n",
    "# Plot titles... decoration...\n",
    "titulos_use = ['disc. Real','disc. Fake','gen. Wasserstein','gen. MSE']\n",
    "\n",
    "\n",
    "step_mean_d1_loss = 0\n",
    "step_mean_d2_loss = 0\n",
    "step_mean_dgrad_loss = 0\n",
    "step_mean_g_loss = 0\n",
    "step_mean_g_comp_loss = 0\n",
    "\n",
    "RESOL_INI = 0\n",
    "\n",
    "# Create tensorboard writer\n",
    "tb_writer = tf.summary.create_file_writer(TENSORBOARD_OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for idx_resol in range(RESOL_INI,LOW_RES_POW):\n",
    "    \n",
    "    # Set current resolution shape\n",
    "    current_shape = [int(input_size[0]/(2**(LOW_RES_POW-idx_resol-1))),\n",
    "                 int(input_size[1]/(2**(LOW_RES_POW-idx_resol-1))),\n",
    "                 int(input_size[2]/(2**(LOW_RES_POW-idx_resol-1)))]\n",
    "    current_shape_string = '%dx%dx%d'%(current_shape[0],current_shape[1],current_shape[2])\n",
    "\n",
    "    \n",
    "    # Select Dataset\n",
    "    dist_dataset_train_GAN = train_datasets_dist_list[LOW_RES_POW-idx_resol-1]\n",
    "    dist_dataset_validation_GAN = validation_datasets_dist_list[LOW_RES_POW-idx_resol-1]\n",
    "    \n",
    "    dataset_train_GAN = train_datasets_list[LOW_RES_POW-idx_resol-1]\n",
    "    dataset_validation_GAN = validation_datasets_list[LOW_RES_POW-idx_resol-1]\n",
    "\n",
    "\n",
    "    for idx_type_model in range(2):\n",
    "        \n",
    "        # First model requires no Fade-In\n",
    "        if idx_resol == RESOL_INI and idx_type_model == 0:\n",
    "            continue\n",
    "        FADE_IN = False\n",
    "        if idx_type_model == 0:\n",
    "            FADE_IN = True\n",
    "        # Choose full or fade-in, we start with fade-in models\n",
    "        disc_model = disc_model_list[idx_resol][1-idx_type_model]\n",
    "        gen_model = generator_model_list[idx_resol][1-idx_type_model]\n",
    "        \n",
    "        # Get current number of steps\n",
    "        if FADE_IN:\n",
    "            STEPS_THIS_PHASE = STEPS_PER_PHASE_FADEIN[idx_resol]\n",
    "        else:\n",
    "            STEPS_THIS_PHASE = STEPS_PER_PHASE[idx_resol]\n",
    "        \n",
    "         \n",
    "        \n",
    "        print('---------------------------------------------------------------------')\n",
    "        print('---------------------------------------------------------------------')\n",
    "        print('\\t\\t Resolution %s'%current_shape_string)\n",
    "        if idx_type_model == 0:\n",
    "            print('\\t\\t\\t --- FADEIN ---')\n",
    "        print('\\t\\t Trainig for %d steps'%STEPS_THIS_PHASE)\n",
    "        print('---------------------------------------------------------------------')\n",
    "        print('---------------------------------------------------------------------')\n",
    "        \n",
    "                \n",
    "        # Set trainiers and plots for this resolution\n",
    "        loss_plot = np.zeros((STEPS_THIS_PHASE*STEPS_PER_PRINT,4))      \n",
    "        loss_val_plot = np.zeros((STEPS_THIS_PHASE*STEPS_PER_PLOTS,5))\n",
    "        loss_std_val_plot = np.zeros((STEPS_THIS_PHASE*STEPS_PER_PLOTS,5))\n",
    "        axis_val_plot = np.zeros((STEPS_THIS_PHASE*STEPS_PER_PLOTS,1))\n",
    "        idx_plot = 0\n",
    "        # train normal or straight-through models\n",
    "        train_step_gen_tf_this = tf.function(TRAINING_FUNCTION_GEN)\n",
    "        train_step_disc_tf_this = tf.function(TRAINING_FUNCTION_DISC)\n",
    "        \n",
    "        # Set tensorboard names\n",
    "        tb_plots_namespace = 'Resolution_'+current_shape_string+'_cuts'\n",
    "        tb_validation_metrics_namespace = 'Resolution_'+current_shape_string+'_Validation_metrics'\n",
    "        tb_training_metrics_namespace = 'Resolution_'+current_shape_string+'_Training_metrics'\n",
    "        if idx_type_model == 0:\n",
    "            tb_plots_namespace = tb_plots_namespace+'_fadeIn'\n",
    "            tb_validation_metrics_namespace = tb_validation_metrics_namespace+'_fadeIn'\n",
    "            tb_training_metrics_namespace = tb_training_metrics_namespace+'_fadeIn'\n",
    "        \n",
    "        \n",
    "        with strategy.scope():\n",
    "            \n",
    "            train_d1_loss = keras.metrics.Mean(name='train_d1_loss')\n",
    "            train_d2_loss = keras.metrics.Mean(name='train_d2_loss')\n",
    "            train_dgrad_loss = keras.metrics.Mean(name='train_dgrad_loss')\n",
    "\n",
    "            train_g_loss = keras.metrics.Mean(name='train_g_loss')\n",
    "            train_g_comp_loss = keras.metrics.Mean(name='train_g_comp_loss')\n",
    "\n",
    "        \n",
    "        with tb_writer.as_default():\n",
    "            \n",
    "            step_ini = 0\n",
    "            \n",
    "            for step in range(step_ini, STEPS_THIS_PHASE):\n",
    "                \n",
    "                if step == 0:\n",
    "                    steps_disc_per_gen = steps_disc_per_gen_ini\n",
    "                else:\n",
    "                    steps_disc_per_gen = steps_disc_per_gen_loop\n",
    "\n",
    "                # ---------------------------------------------------------------------------------\n",
    "                # --------------------------- TRAIN DISCRIMINATOR ---------------------------------\n",
    "                # ---------------------------------------------------------------------------------\n",
    "                idx_disc_train = 0\n",
    "                disc_loss_d1_aux = 0\n",
    "                disc_loss_d2_aux = 0\n",
    "                disc_loss_dgrad_aux = 0\n",
    "                for in_NAC_PET, in_LABELS, in_CT in dist_dataset_train_GAN:\n",
    "\n",
    "                    train_step_disc_tf_this(in_NAC_PET,\n",
    "                                            in_CT,\n",
    "                                            gen_model, \n",
    "                                            disc_model, \n",
    "                                            train_d1_loss,\n",
    "                                            train_d2_loss,\n",
    "                                            train_dgrad_loss,\n",
    "                                            optimizer_disc,\n",
    "                                            strategy,\n",
    "                                            K_grad=10.0,\n",
    "                                            cross_sample_loss = False)\n",
    "\n",
    "                    disc_loss_d1_aux += train_d1_loss.result()\n",
    "                    disc_loss_d2_aux += train_d2_loss.result()\n",
    "                    disc_loss_dgrad_aux += train_dgrad_loss.result()\n",
    "\n",
    "\n",
    "                    print_l_real = disc_loss_d1_aux/(idx_disc_train+1)\n",
    "                    print_l_fake = disc_loss_d2_aux/(idx_disc_train+1)\n",
    "                    print_l_grad = disc_loss_dgrad_aux/(idx_disc_train+1)\n",
    "                    print_l_tot = print_l_fake+print_l_real+print_l_grad\n",
    "                    print('(Step: %d) Training Discriminator: %d/%d\\tLoss: %.4f (Real:%.4f Fake:%.4f Grad.:%.4f)      '%(step,\n",
    "                                                                                                                          idx_disc_train+1,\n",
    "                                                                                                                          steps_disc_per_gen,\n",
    "                                                                                                                          print_l_tot,\n",
    "                                                                                                                          print_l_real,\n",
    "                                                                                                                          print_l_fake,\n",
    "                                                                                                                          print_l_grad), end='')\n",
    "                    print('', end='\\r')\n",
    "\n",
    "\n",
    "                    idx_disc_train += 1\n",
    "                    if idx_disc_train == steps_disc_per_gen:\n",
    "                        last_fake_score_module = tf.abs(print_l_fake)\n",
    "                        break\n",
    "\n",
    "                with tf.name_scope(tb_training_metrics_namespace):\n",
    "                    tf.summary.scalar(\"Disc. Real\", print_l_real, step=step)\n",
    "                    tf.summary.scalar(\"Disc. Fake\", print_l_fake, step=step)\n",
    "                    tf.summary.scalar(\"Disc. Grad\", print_l_grad, step=step)\n",
    "                    tf.summary.scalar(\"Disc. Full\", print_l_tot, step=step)\n",
    "\n",
    "                # ---------------------------------------------------------------------------------\n",
    "                # --------------------------- TRAIN GENERATOR -------------------------------------\n",
    "                # ---------------------------------------------------------------------------------\n",
    "                for in_NAC_PET, in_LABELS, in_CT in dist_dataset_train_GAN:\n",
    "\n",
    "                    print('(Step: %d) Training Generator...                                                                             '%(step), end='')\n",
    "                    print('', end='\\r')\n",
    "\n",
    "                    train_step_gen_tf_this(in_NAC_PET,\n",
    "                                           in_CT,\n",
    "                                           gen_model, \n",
    "                                           disc_model, \n",
    "                                           train_g_loss,\n",
    "                                           train_g_comp_loss,\n",
    "                                           optimizer_gen,\n",
    "                                           strategy,\n",
    "                                           K_comp_loss = 1.0/100.0,\n",
    "                                           norm_by_size = False)\n",
    "\n",
    "\n",
    "\n",
    "                    break\n",
    "\n",
    "\n",
    "                loss_plot[step,0] = disc_loss_d1_aux/steps_disc_per_gen\n",
    "                loss_plot[step,1] = disc_loss_d2_aux/steps_disc_per_gen\n",
    "                loss_plot[step,2] = train_g_loss.result()\n",
    "                loss_plot[step,3] = train_g_comp_loss.result()    \n",
    "\n",
    "\n",
    "                with tf.name_scope(tb_training_metrics_namespace):\n",
    "                    tf.summary.scalar(\"Gen. WGAN loss\", train_g_loss.result(), step=step)\n",
    "                    tf.summary.scalar(\"Gen. L2 loss\", train_g_comp_loss.result(), step=step)\n",
    "\n",
    "\n",
    "\n",
    "                train_d1_loss.reset_states()\n",
    "                train_d2_loss.reset_states()\n",
    "                train_dgrad_loss.reset_states()\n",
    "                train_g_loss.reset_states()\n",
    "                train_g_comp_loss.reset_states()\n",
    "\n",
    "                step_mean_d1_loss += loss_plot[step,0]\n",
    "                step_mean_d2_loss += loss_plot[step,1]\n",
    "                step_mean_dgrad_loss += disc_loss_dgrad_aux/steps_disc_per_gen\n",
    "                step_mean_g_loss += loss_plot[step,2]\n",
    "                step_mean_g_comp_loss += loss_plot[step,3]\n",
    "                \n",
    "                \n",
    "                # ---------------------------------------------------------------------------------\n",
    "                # --------------------------- TRAIN METRICS ---------------------------------------\n",
    "                # ---------------------------------------------------------------------------------\n",
    "\n",
    "                if step%STEPS_PER_PRINT == 0:\n",
    "\n",
    "                    if step != 0:\n",
    "                        step_mean_d1_loss = step_mean_d1_loss/float(STEPS_PER_PRINT)\n",
    "                        step_mean_d2_loss = step_mean_d2_loss/float(STEPS_PER_PRINT)\n",
    "                        step_mean_g_loss = step_mean_g_loss/float(STEPS_PER_PRINT)\n",
    "                        step_mean_g_comp_loss = step_mean_g_comp_loss/float(STEPS_PER_PRINT)\n",
    "                        step_mean_dgrad_loss = step_mean_dgrad_loss/float(STEPS_PER_PRINT)\n",
    "\n",
    "                    step_mean_dtot_loss = step_mean_d1_loss+step_mean_d2_loss+step_mean_dgrad_loss\n",
    "\n",
    "                    print('>%d, d1=%.4f, d2=%.4f, dg=%.4f (d=%.4f) ; g=%.4f g_comp=%.4f ' % (step, \n",
    "                                                                                             step_mean_d1_loss, \n",
    "                                                                                             step_mean_d2_loss,\n",
    "                                                                                             step_mean_dgrad_loss,\n",
    "                                                                                             step_mean_dtot_loss,\n",
    "                                                                                             step_mean_g_loss,\n",
    "                                                                                             step_mean_g_comp_loss))\n",
    "\n",
    "                    step_mean_d1_loss = 0\n",
    "                    step_mean_d2_loss = 0\n",
    "                    step_mean_dgrad_loss = 0\n",
    "                    step_mean_g_loss = 0\n",
    "                    step_mean_g_comp_loss = 0\n",
    "\n",
    "\n",
    "                if step%STEPS_PER_PLOTS == 0 and step > 0:\n",
    "\n",
    "                    GAN.train_support.plot_loss(loss_plot, step, forma='2_cols', dpi_use=100, titulos=titulos_use, skip_n_initial=10)\n",
    "\n",
    "\n",
    "\n",
    "                    (PET_INPUT_images, \n",
    "                     CT_INPUT_images, \n",
    "                     LABELS_INPUT_images, \n",
    "                     CT_SYNTH_images, \n",
    "                     SEGMENTED_images, \n",
    "                     SCORE_images, \n",
    "                     PSNR_images, \n",
    "                     ME_images, \n",
    "                     NMSE_images, \n",
    "                     NCC_images) = GAN.train_support.validate_whole_volume(gen_model, \n",
    "                                                                           disc_model, \n",
    "                                                                           dataset_validation_GAN, \n",
    "                                                                           current_shape, \n",
    "                                                                           segm_net = False)\n",
    "                    print('')\n",
    "                    with tf.name_scope(tb_plots_namespace):\n",
    "                        GAN.train_support.plot_images3D_conditional(PET_INPUT_images,\n",
    "                                                                    CT_INPUT_images, \n",
    "                                                                    CT_SYNTH_images, \n",
    "                                                                    segm_net = False,\n",
    "                                                                    dpi_use = 150,\n",
    "                                                                    add_tensorboard=True, \n",
    "                                                                    epoch=step)\n",
    "\n",
    "                    print('Metrics:                              ')\n",
    "                    print('\\tCritic Score:\\t mean=%0.5f ; std=%0.5f'%(np.array(SCORE_images).mean(),np.array(SCORE_images).std()))\n",
    "                    print('\\tPSNR:\\t\\t mean=%0.5f ; std=%0.5f'%(np.array(PSNR_images).mean(),np.array(PSNR_images).std()))\n",
    "                    print('\\tME:\\t\\t mean=%0.5f ; std=%0.5f'%(np.array(ME_images).mean(),np.array(ME_images).std()))\n",
    "                    print('\\tNMSE:\\t\\t mean=%0.5f ; std=%0.5f'%(np.array(NMSE_images).mean(),np.array(NMSE_images).std()))\n",
    "                    print('\\tNCC:\\t\\t mean=%0.5f ; std=%0.5f'%(np.array(NCC_images).mean(),np.array(NCC_images).std()))\n",
    "\n",
    "\n",
    "                    with tf.name_scope(tb_validation_metrics_namespace):\n",
    "                        tf.summary.scalar(\"Critic_Score\", np.array(SCORE_images).mean(), step=step)\n",
    "                        tf.summary.scalar(\"PSNR\", np.array(PSNR_images).mean(), step=step)\n",
    "                        tf.summary.scalar(\"ME\", np.array(ME_images).mean(), step=step)\n",
    "                        tf.summary.scalar(\"NMSE\", np.array(NMSE_images).mean(), step=step)\n",
    "                        tf.summary.scalar(\"NCC\", np.array(NCC_images).mean(), step=step)\n",
    "\n",
    "\n",
    "                    loss_val_plot[idx_plot, 0] = np.array(SCORE_images).mean()\n",
    "                    loss_val_plot[idx_plot, 1] = np.array(PSNR_images).mean()\n",
    "                    loss_val_plot[idx_plot, 2] = np.array(ME_images).mean()\n",
    "                    loss_val_plot[idx_plot, 3] = np.array(NMSE_images).mean()\n",
    "                    loss_val_plot[idx_plot, 4] = np.array(NCC_images).mean()\n",
    "\n",
    "                    loss_std_val_plot[idx_plot, 0] = np.array(SCORE_images).std()\n",
    "                    loss_std_val_plot[idx_plot, 1] = np.array(PSNR_images).std()\n",
    "                    loss_std_val_plot[idx_plot, 2] = np.array(ME_images).std()\n",
    "                    loss_std_val_plot[idx_plot, 3] = np.array(NMSE_images).std()\n",
    "                    loss_std_val_plot[idx_plot, 4] = np.array(NCC_images).std()\n",
    "\n",
    "                    axis_val_plot[idx_plot, 0] = step\n",
    "                    idx_plot += 1\n",
    "\n",
    "\n",
    "                    plt.figure(dpi=100)\n",
    "                    plt.subplot(3,2,1)\n",
    "                    plt.errorbar(axis_val_plot[:idx_plot,0], loss_val_plot[:idx_plot,0], yerr=loss_std_val_plot[:idx_plot,0], fmt='-o')\n",
    "                    plt.grid('on')\n",
    "                    plt.title('Critic score')\n",
    "                    plt.subplot(3,2,2)\n",
    "                    plt.errorbar(axis_val_plot[:idx_plot,0], loss_val_plot[:idx_plot,1], yerr=loss_std_val_plot[:idx_plot,1], fmt='-o')\n",
    "                    plt.grid('on')\n",
    "                    plt.title('PSNR')\n",
    "                    plt.subplot(3,2,3)\n",
    "                    plt.errorbar(axis_val_plot[:idx_plot,0], loss_val_plot[:idx_plot,2], yerr=loss_std_val_plot[:idx_plot,2], fmt='-o')\n",
    "                    plt.grid('on')\n",
    "                    plt.title('ME')\n",
    "                    plt.subplot(3,2,4)\n",
    "                    plt.errorbar(axis_val_plot[:idx_plot,0], loss_val_plot[:idx_plot,3], yerr=loss_std_val_plot[:idx_plot,3], fmt='-o')\n",
    "                    plt.grid('on')\n",
    "                    plt.title('NMSE')\n",
    "                    plt.subplot(3,2,5)\n",
    "                    plt.errorbar(axis_val_plot[:idx_plot,0], loss_val_plot[:idx_plot,4], yerr=loss_std_val_plot[:idx_plot,4], fmt='-o')\n",
    "                    plt.grid('on')\n",
    "                    plt.title('NCC')\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "\n",
    "                   \n",
    "                    plt.close('all')\n",
    "\n",
    "\n",
    "                tb_writer.flush()\n",
    "\n",
    "\n",
    "                if step%STEPS_PER_SAVE == 0 and step > 0:\n",
    "                    CHECKPOINT_PATH_NET_RESOLUTION = os.path.join(CHECKPOINT_PATH, 'Res_'+current_shape_string)\n",
    "                    File_mng.check_create_path('CHECKPOINT_PATH_NET_RESOLUTION', CHECKPOINT_PATH_NET_RESOLUTION, clear_folder=False) \n",
    "\n",
    "                    GAN.train_support.save_progressive_model(generator_model_list, \n",
    "                                                             disc_model_list,\n",
    "                                                             input_size, \n",
    "                                                             NETWORK_NAME, \n",
    "                                                             CHECKPOINT_PATH_NET_RESOLUTION, \n",
    "                                                             0,\n",
    "                                                             save_limit=idx_resol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
